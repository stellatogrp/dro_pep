# Problem parameters
n: 50                   # Dimension of beta
N_data: 300            # Number of data points per problem
p_beta_nonzero: 0.3     # Sparsity of true beta
delta: 0.0             # L2 regularization parameter (equals mu)

# Computed on-the-fly if null
L: 6.200262             # Lipschitz constant (from A matrix)
R: 2.896123             # Initial radius (from optimal solutions)

beta_scale: 3.0         # Beta entries uniform in [-beta_scale, beta_scale]
A_std: 1.0              # Standard deviation for A matrix entries
eps_std: 0.1            # Standard deviation for label noise

# Sample sizes
N: 20                   # Batch size for SGD training
L_sample_size: 1000     # Number of A samples for worst-case L computation
R_sample_size: 100      # Number of (A, b) samples for R computation
precond_sample_size: 100  # Number of samples for preconditioner

# Random seeds
seed: 50                # SGD randomness
A_seed: 1000            # (deprecated - A now sampled per iteration)
L_seed: 1001            # Seed for L computation
R_seed: 5002            # Seed for R computation

# Learning framework
learning_framework: 'lpep'  # Options: 'ldro-pep', 'l2o', 'lpep'

# Algorithm and optimizer settings
alg: 'vanilla_gd'       # Options: 'vanilla_gd', 'nesterov_fgm'
optimizer_type: 'adamw' # Options: 'vanilla_sgd', 'adamw', 'sgd_wd'
stepsize_type: 'vector' # Options: 'scalar', 'vector'
vector_init: 'fixed'    # Options: 'fixed', 'silver'

# K_max values
# K_max: [5, 10, 15, 20]
K_max: [15]

# Optimization hyperparameters
pep_obj: 'obj_val'          # Options: 'obj_val', 'opt_dist_sq_norm', 'grad_sq_norm'
dro_obj: 'expectation'      # Options: 'expectation', 'cvar'
sdp_backend: 'scs'          # Options: 'scs', 'clarabel'
dro_canon_backend: 'manual_jax'  # Options: 'manual_jax', 'cvxpylayers'
eps: 0.1                    # Wasserstein ball radius
alpha: 0.1                  # CVaR confidence level

# L2O-specific loss formulations (only used when learning_framework='l2o')
l2o_loss_type: 'weighted'      # Options: 'final', 'cumulative', 'weighted', 'per_step', 'distance_cumulative'
l2o_decay_rate: 0.9         # Decay rate for 'weighted' loss type
precond_type: 'average'     # Preconditioner type

learn_beta: True           # Whether to learn beta (only for nesterov_fgm)

# SGD training parameters
sgd_iters: 500               # Number of SGD iterations
eta_t: 1e-3                 # Learning rate for stepsizes
weight_decay: 1e-2          # Weight decay for sgd_wd optimizer

# MOSEK solver tolerances
mosek_tol_dfeas: 1e-2
mosek_tol_pfeas: 1e-2
mosek_tol_rel_gap: 1e-2

# Outputs
output_dir: 'learn_dro_outputs'

# Training and out-of-sample configuration
training_sample_N: 500          # Number of training samples (pre-sampled)
out_of_sample_val_N: 500       # Number of validation samples (in-distribution)
out_of_sample_test_N: 1000     # Number of test samples (in-distribution)
out_of_sample_val_seed: 10000  # Seed for generating validation problems
out_of_sample_test_seed: 20000 # Seed for generating test problems
out_of_dist_N: 1000            # Number of out-of-distribution test samples
out_of_dist_seed: 30000        # Seed for generating out-of-distribution problems
A_out_of_dist_seed: 4000       # Seed for out-of-distribution A matrix
A_out_of_dist_std_multiplier: 2.0  # Multiplier for A_std in out-of-distribution
